"""
–§–ò–ù–ê–õ–¨–ù–´–ô –ü–ê–†–°–ï–† –¢–ï–ù–î–ï–†–û–í REESTR.NADLOC.KZ
–°–æ–∑–¥–∞–µ—Ç –¢–†–ò CSV —Ñ–∞–π–ª–∞:
1. tenders_list.csv - —Å–ø–∏—Å–æ–∫ —Ç–µ–Ω–¥–µ—Ä–æ–≤ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã —Ä–µ–µ—Å—Ç—Ä–∞
2. completed_tenders.csv - –¥–µ—Ç–∞–ª–∏ –ó–ê–í–ï–†–®–ï–ù–ù–´–• —Ç–µ–Ω–¥–µ—Ä–æ–≤ (–ø—Ä–æ—Ç–æ–∫–æ–ª—ã)
3. published_tenders.csv - –¥–µ—Ç–∞–ª–∏ –û–ü–£–ë–õ–ò–ö–û–í–ê–ù–ù–´–• —Ç–µ–Ω–¥–µ—Ä–æ–≤ (–æ–±—ä—è–≤–ª–µ–Ω–∏—è)
"""

import aiohttp
import asyncio
import csv
from bs4 import BeautifulSoup
from datetime import datetime
import ssl
from typing import List, Dict, Optional
import logging
import re
from urllib.parse import urljoin

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class AdvancedTenderParser:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø–∞—Ä—Å–µ—Ä —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ç–∏–ø–∞ —Ç–µ–Ω–¥–µ—Ä–∞"""

    def __init__(self, base_url: str = "https://www.reestr.nadloc.kz"):
        self.base_url = base_url
        self.session = None
        self.tenders_list = []
        self.completed_tenders = []  # –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ
        self.published_tenders = []  # –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8',
        }

    async def __aenter__(self):
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE

        connector = aiohttp.TCPConnector(ssl=ssl_context, limit=5)
        timeout = aiohttp.ClientTimeout(total=60)
        self.session = aiohttp.ClientSession(
            connector=connector,
            headers=self.headers,
            timeout=timeout
        )
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
            await asyncio.sleep(0.25)

    async def fetch_page(self, url: str, retry: int = 3) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        for attempt in range(retry):
            try:
                async with self.session.get(url) as response:
                    if response.status == 200:
                        return await response.text()
                    else:
                        logger.warning(f"–°—Ç–∞—Ç—É—Å {response.status} –¥–ª—è {url}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}: {e}")
                if attempt < retry - 1:
                    await asyncio.sleep(2 ** attempt)
        return None

    # =========================================================================
    # –ü–ê–†–°–ò–ù–ì –°–ü–ò–°–ö–ê –¢–ï–ù–î–ï–†–û–í
    # =========================================================================

    def parse_tender_list_table(self, html: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã"""
        soup = BeautifulSoup(html, 'html.parser')
        tenders = []

        table = soup.find('table')
        if not table:
            return []

        rows = table.find_all('tr')[1:]
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(rows)} —Å—Ç—Ä–æ–∫")

        for idx, row in enumerate(rows, 1):
            try:
                tender = self.parse_tender_row(row)
                if tender:
                    tenders.append(tender)
                    logger.info(f"  ‚úì [{idx}] {tender.get('code', 'N/A')[:50]}")
            except Exception as e:
                logger.error(f"  ‚úó –û—à–∏–±–∫–∞ —Å—Ç—Ä–æ–∫–∏ {idx}: {e}")

        return tenders

    def parse_tender_row(self, row) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã"""
        cells = row.find_all('td')
        if len(cells) < 7:
            return None

        tender = {}

        try:
            code_cell = cells[0]
            link = code_cell.find('a', href=True)
            if link:
                tender['code'] = link.get_text(strip=True)
                tender['detail_link'] = urljoin(self.base_url, link['href'])
                tender['description'] = code_cell.get_text(strip=True).replace(tender['code'], '').strip()
            else:
                tender['code'] = code_cell.get_text(strip=True)
                tender['detail_link'] = None

            tender['customer'] = cells[1].get_text(strip=True)
            tender['lots'] = cells[2].get_text(strip=True)
            tender['planned_amount'] = cells[3].get_text(strip=True) or '-'
            tender['purchase_amount'] = cells[4].get_text(strip=True)
            tender['method'] = cells[5].get_text(strip=True)

            status_cell = cells[6]
            tender['status'] = status_cell.get_text(strip=True)

            if len(cells) >= 8:
                tender['dates'] = cells[7].get_text(strip=True)

            return tender
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏: {e}")
            return None

    async def parse_page_list(self, page_num: int) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–ø–∏—Å–∫–∞"""
        url = f"{self.base_url}/ru/tender/list?page={page_num}"
        logger.info(f"\n{'=' * 70}")
        logger.info(f"–°–¢–†–ê–ù–ò–¶–ê {page_num}: {url}")
        logger.info(f"{'=' * 70}")

        html = await self.fetch_page(url)
        if not html:
            return []

        tenders = self.parse_tender_list_table(html)
        logger.info(f"‚úì –ü–æ–ª—É—á–µ–Ω–æ {len(tenders)} —Ç–µ–Ω–¥–µ—Ä–æ–≤")

        return tenders

    # =========================================================================
    # –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –¢–ò–ü–ê –¢–ï–ù–î–ï–†–ê –ò –ü–ê–†–°–ò–ù–ì
    # =========================================================================

    async def parse_tender_detail(self, tender: Dict) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ç–∏–ø–∞"""
        detail_link = tender.get('detail_link')
        if not detail_link:
            return {}

        tender_code = tender.get('code', 'N/A')
        logger.info(f"  ‚Üí {tender_code[:50]}")

        html = await self.fetch_page(detail_link)
        if not html:
            return {}

        soup = BeautifulSoup(html, 'html.parser')
        text = soup.get_text()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç–µ–Ω–¥–µ—Ä–∞
        is_completed = any(x in text for x in [
            '–ü—Ä–æ—Ç–æ–∫–æ–ª –ø–æ–¥–≤–µ–¥–µ–Ω–∏—è –∏—Ç–æ–≥–æ–≤',
            '—Å–ø–æ—Å–æ–±–æ–º –∏–∑ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞',
            '–ü—Ä–µ–¥–º–µ—Ç –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏—è –¢–†–£ —Å–ø–æ—Å–æ–±–æ–º'
        ])

        is_published = any(x in text for x in [
            '–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –∏ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è',
            '–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –≤—Å–∫—Ä—ã—Ç–∏—è',
            '–ü—Ä–µ–¥–º–µ—Ç –∑–∞–∫—É–ø–∞ —Å–ø–æ—Å–æ–±–æ–º —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É'
        ])

        if is_completed:
            logger.info(f"    ‚ÑπÔ∏è –¢–∏–ø: –ó–ê–í–ï–†–®–ï–ù–ù–´–ô")
            detail = self.parse_completed_tender(soup, text, tender_code, detail_link)
            return {'type': 'completed', 'data': detail}
        elif is_published:
            logger.info(f"    ‚ÑπÔ∏è –¢–∏–ø: –û–ü–£–ë–õ–ò–ö–û–í–ê–ù–ù–´–ô")
            detail = self.parse_published_tender(soup, text, tender_code, detail_link)
            return {'type': 'published', 'data': detail}
        else:
            logger.warning(f"    ‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø")
            return {'type': 'unknown', 'data': {}}

    # =========================================================================
    # –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–ï–ù–ù–´–• –¢–ï–ù–î–ï–†–û–í
    # =========================================================================

    def parse_completed_tender(self, soup, text: str, tender_code: str, link: str) -> Dict:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –ó–ê–í–ï–†–®–ï–ù–ù–û–ì–û —Ç–µ–Ω–¥–µ—Ä–∞"""
        detail = {
            'tender_code': tender_code,
            'detail_link': link
        }

        try:
            # 1. –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫–∞
            match = re.search(r'1\.\s*–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫–∞[:\s]*(.*?)(?=\n2\.|\n\n)', text, re.DOTALL)
            if match:
                detail['customer_name'] = match.group(1).strip()

            # 2. –ú–µ—Å—Ç–æ–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ
            match = re.search(r'2\.\s*–ú–µ—Å—Ç–æ–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫–∞[:\s]*(.*?)(?=\n3\.|\n\n)', text, re.DOTALL)
            if match:
                detail['customer_location'] = match.group(1).strip()[:500]

            # 3. –û—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è –∑–∞–∫—É–ø–∞
            match = re.search(r'3\.\s*–û—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è –∑–∞–∫—É–ø–∞.*?:(.*?)(?=\n4\.|\n\n)', text, re.DOTALL)
            if match:
                detail['purchase_basis'] = match.group(1).strip()[:1000]

            # 4. –ü—Ä–µ–¥–º–µ—Ç –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏—è - –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ª–æ—Ç–æ–≤
            lots_section = re.search(r'4\.\s*–ü—Ä–µ–¥–º–µ—Ç –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏—è.*?(?=5\.|$)', text, re.DOTALL)
            if lots_section:
                lots_text = lots_section.group(0)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –ª–æ—Ç—ã
                lot_patterns = re.findall(
                    r'–ù–æ–º–µ—Ä –∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ª–æ—Ç–∞:\s*(\d+),\s*(.*?)\s*–°—É–º–º–∞.*?(\d[\d\s,.]+)\s*—Ç–µ–Ω–≥–µ', lots_text,
                    re.DOTALL)

                if lot_patterns:
                    lots_info = []
                    for lot_num, lot_name, lot_sum in lot_patterns:
                        lots_info.append(f"–õ–æ—Ç {lot_num}: {lot_name.strip()} - {lot_sum.strip()} —Ç–≥")
                    detail['lots_description'] = ' | '.join(lots_info)
                    detail['total_lots'] = len(lot_patterns)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –°–ö–ü
                skp_items = []
                tables = soup.find_all('table')
                for table in tables:
                    if '–ö–æ–¥ –°–ö–ü' in table.get_text():
                        rows = table.find_all('tr')[1:]
                        for row in rows[:10]:  # –ü–µ—Ä–≤—ã–µ 10 –ø–æ–∑–∏—Ü–∏–π
                            cells = row.find_all('td')
                            if len(cells) >= 4:
                                code = cells[0].get_text(strip=True)
                                descr = cells[1].get_text(strip=True)[:100]
                                unit = cells[2].get_text(strip=True)
                                qty = cells[3].get_text(strip=True)
                                skp_items.append(f"{code}|{descr}|{unit}|{qty}")
                        break

                if skp_items:
                    detail['skp_items'] = ' || '.join(skp_items)

            # 5. –õ–∏—Ü–µ–Ω–∑–∏–∏
            licenses_section = re.search(r'5\.\s*–ù–æ–º–µ—Ä–∞ –ª–∏—Ü–µ–Ω–∑–∏–∏.*?:(.*?)(?=6\.|$)', text, re.DOTALL)
            if licenses_section:
                licenses_text = licenses_section.group(1)
                licenses = re.findall(r'–õ–∏—Ü–µ–Ω–∑–∏—è\(–∫–æ–Ω—Ç—Ä–∞–∫—Ç\)\s*‚Ññ\s*(\d+)\s*–æ—Ç\s*([\d.]+)', licenses_text)
                if licenses:
                    lic_list = [f"‚Ññ{lic[0]} –æ—Ç {lic[1]}" for lic in licenses]
                    detail['licenses'] = ' | '.join(lic_list)

            # 6. –ü–æ—Å—Ç–∞–≤—â–∏–∫–∏ - –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ —Ç–∞–±–ª–∏—Ü
            suppliers_section = re.search(r'6\.\s*–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞.*?(?=7\.|$)', text, re.DOTALL)
            if suppliers_section:
                suppliers = []
                for table in soup.find_all('table'):
                    if '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ' in table.get_text() and '–ø–æ—Å—Ç–∞–≤—â–∏–∫–∞' in table.get_text():
                        rows = table.find_all('tr')[1:]
                        for row in rows[:5]:
                            cells = row.find_all('td')
                            if len(cells) >= 2:
                                supplier_name = cells[1].get_text(strip=True)[:200]
                                supplier_addr = cells[2].get_text(strip=True)[:200] if len(cells) > 2 else ''
                                delivery_period = cells[3].get_text(strip=True) if len(cells) > 3 else ''
                                delivery_place = cells[4].get_text(strip=True)[:100] if len(cells) > 4 else ''

                                suppliers.append(f"{supplier_name}|{supplier_addr}|{delivery_period}|{delivery_place}")
                        break

                if suppliers:
                    detail['suppliers'] = ' || '.join(suppliers)
                    # –ü–µ—Ä–≤—ã–π –æ–±—ã—á–Ω–æ –ø–æ–±–µ–¥–∏—Ç–µ–ª—å
                    if suppliers:
                        parts = suppliers[0].split('|')
                        detail['winner_supplier'] = parts[0]
                        if len(parts) > 1:
                            detail['winner_address'] = parts[1]

            # 7. –¶–µ–Ω—ã
            prices_section = re.search(r'7\.\s*–¶–µ–Ω–∞, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–∞—è.*?(?=8\.|$)', text, re.DOTALL)
            if prices_section:
                prices = []
                for table in soup.find_all('table'):
                    if '–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–∞—è —Ü–µ–Ω–∞' in table.get_text() or '–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–∞—è —Ü–µ–Ω–∞' in table.get_text():
                        rows = table.find_all('tr')[1:]
                        for row in rows[:5]:
                            cells = row.find_all('td')
                            if len(cells) >= 3:
                                supplier = cells[1].get_text(strip=True)[:100]
                                price = cells[2].get_text(strip=True)
                                local_content = cells[3].get_text(strip=True) if len(cells) > 3 else ''

                                prices.append(f"{supplier}|{price}|{local_content}")
                        break

                if prices:
                    detail['all_prices'] = ' || '.join(prices)
                    # –ü–µ—Ä–≤–∞—è —Ü–µ–Ω–∞ - –ø–æ–±–µ–¥–∏—Ç–µ–ª—å
                    if prices:
                        parts = prices[0].split('|')
                        detail['winner_price'] = parts[1] if len(parts) > 1 else parts[0]
                        if len(parts) > 2:
                            detail['local_content'] = parts[2]

            # 8. –ö–æ–¥ –∑–∞–∫—É–ø–∫–∏
            match = re.search(r'8\.\s*–ö–æ–¥ –∑–∞–∫—É–ø–∫–∏[:\s]*([A-Z]+[\w\.\-]+)', text)
            if match:
                detail['purchase_code'] = match.group(1)

            # –ü–æ–¥–ø–∏—Å—å
            match = re.search(r'–ò–º—è –ø–æ–¥–ø–∏—Å–∞–≤—à–µ–≥–æ:\s*([^\n]+)', text)
            if match:
                detail['signed_by'] = match.group(1).strip()

            match = re.search(r'–î–∞—Ç–∞ –ø–æ–¥–ø–∏—Å–∏:\s*(\d{2}\.\d{2}\.\d{4}\s+\d{2}:\d{2}:\d{2})', text)
            if match:
                detail['signed_date'] = match.group(1).strip()

            logger.info(f"    ‚úì –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(detail)} –ø–æ–ª–µ–π")

        except Exception as e:
            logger.error(f"    ‚úó –û—à–∏–±–∫–∞: {e}")

        return detail

    # =========================================================================
    # –ü–ê–†–°–ò–ù–ì –û–ü–£–ë–õ–ò–ö–û–í–ê–ù–ù–´–• –¢–ï–ù–î–ï–†–û–í
    # =========================================================================

    def parse_published_tender(self, soup, text: str, tender_code: str, link: str) -> Dict:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –û–ü–£–ë–õ–ò–ö–û–í–ê–ù–ù–û–ì–û —Ç–µ–Ω–¥–µ—Ä–∞"""
        detail = {
            'tender_code': tender_code,
            'detail_link': link
        }

        try:
            # 1. –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫–∞
            match = re.search(r'1\.\s*–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫–∞.*?\n(.*?)(?=\t|$)', text, re.MULTILINE)
            if match:
                detail['customer_name'] = match.group(1).strip()

            # –ê–¥—Ä–µ—Å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Ä–µ—Å—É—Ä—Å–∞
            match = re.search(r'–ê–¥—Ä–µ—Å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Ä–µ—Å—É—Ä—Å–∞\s*(https?://[\w\.\-/]+)', text)
            if match:
                detail['web_resource'] = match.group(1)

            # –ú–µ—Å—Ç–æ–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ
            match = re.search(r'–ú–µ—Å—Ç–æ–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –∑–∞–∫–∞–∑—á–∏–∫–∞.*?\n(.*?)(?=\n2\.|\n\n)', text, re.DOTALL)
            if match:
                detail['customer_location'] = match.group(1).strip()[:300]

            # 2. –ü—Ä–µ–¥–º–µ—Ç –∑–∞–∫—É–ø–∞ - –∏–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
            positions = []
            tables = soup.find_all('table')
            for table in tables:
                if '–ö–æ–¥ –°–ö–ü' in table.get_text() and '–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ' in table.get_text():
                    rows = table.find_all('tr')[1:]

                    for row in rows[:50]:  # –ü–µ—Ä–≤—ã–µ 50 –ø–æ–∑–∏—Ü–∏–π
                        cells = row.find_all('td')
                        if len(cells) >= 5:
                            # –õ–û–¢ ‚Ññ, –ö–æ–¥ –°–ö–ü, –û–ø–∏—Å–∞–Ω–∏–µ, –ï–¥–∏–Ω–∏—Ü–∞, –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ, –°—É–º–º–∞, –°—Ä–æ–∫, –ú–µ—Å—Ç–æ
                            lot_num = cells[0].get_text(strip=True) if cells[0].get_text(strip=True) else 'N/A'
                            skp_code = cells[1].get_text(strip=True)
                            description = cells[2].get_text(strip=True)[:100]
                            unit = cells[3].get_text(strip=True)
                            quantity = cells[4].get_text(strip=True)
                            amount = cells[5].get_text(strip=True) if len(cells) > 5 else ''
                            delivery_days = cells[6].get_text(strip=True) if len(cells) > 6 else ''
                            delivery_place = cells[7].get_text(strip=True)[:150] if len(cells) > 7 else ''

                            positions.append(
                                f"{skp_code}|{description}|{unit}|{quantity}|{amount}|{delivery_days}|{delivery_place}")

                    break

            if positions:
                detail['purchase_items'] = ' || '.join(positions)
                detail['total_items'] = len(positions)

            # 3. –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –∏ –æ–∫–æ–Ω—á–∞–Ω–∏—è
            match = re.search(r'–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞.*?\n([\d\.\s:]+)', text)
            if match:
                detail['submission_start'] = match.group(1).strip()

            match = re.search(r'–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è.*?\n([\d\.\s:]+)', text)
            if match:
                detail['submission_end'] = match.group(1).strip()

            match = re.search(r'–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –≤—Å–∫—Ä—ã—Ç–∏—è.*?\n([\d\.\s:]+)', text)
            if match:
                detail['opening_date'] = match.group(1).strip()

            # 4. –ö–æ–Ω—Ç–∞–∫—Ç—ã
            match = re.search(r'–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã.*?\n([\w\.\-@]+)', text)
            if match:
                detail['contact_email'] = match.group(1).strip()

            match = re.search(r'–ù–æ–º–µ—Ä –∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–≥–æ —Ç–µ–ª–µ—Ñ–æ–Ω–∞.*?\n([\d\s\+\(\)]+)', text)
            if match:
                detail['contact_phone'] = match.group(1).strip()

            # 6. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–æ –º–µ—Å—Ç–Ω–æ–º—É —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é
            match = re.search(r'–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–æ –º–µ—Å—Ç–Ω–æ–º—É —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é.*?\n([\d\s%]+)', text)
            if match:
                detail['local_content_requirement'] = match.group(1).strip()

            # –°—Ä–æ–∫ –∑–∞–∫–ª—é—á–µ–Ω–∏—è –¥–æ–≥–æ–≤–æ—Ä–∞
            match = re.search(r'–¢—Ä–µ–±—É–µ–º—ã–π —Å—Ä–æ–∫ –∑–∞–∫–ª—é—á–µ–Ω–∏—è –¥–æ–≥–æ–≤–æ—Ä–∞.*?\n(.*?)(?=\t|\n)', text)
            if match:
                detail['contract_deadline'] = match.group(1).strip()

            # –ü–æ–¥–ø–∏—Å—å
            match = re.search(r'–ò–º—è –ø–æ–¥–ø–∏—Å–∞–≤—à–µ–≥–æ:\s*([^\t\n]+)', text)
            if match:
                detail['signed_by'] = match.group(1).strip()

            match = re.search(r'–î–∞—Ç–∞ –ø–æ–¥–ø–∏—Å–∏:\s*(\d{2}\.\d{2}\.\d{4}\s+\d{2}:\d{2}:\d{2})', text)
            if match:
                detail['signed_date'] = match.group(1).strip()

            logger.info(f"    ‚úì –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(detail)} –ø–æ–ª–µ–π")

        except Exception as e:
            logger.error(f"    ‚úó –û—à–∏–±–∫–∞: {e}")

        return detail

    # =========================================================================
    # –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê
    # =========================================================================

    async def parse_all(self, start_page: int = 1, end_page: int = 3):
        """–ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥"""
        print("\n" + "=" * 70)
        print("–≠–¢–ê–ü 1: –ü–ê–†–°–ò–ù–ì –°–ü–ò–°–ö–ê")
        print("=" * 70)

        for page in range(start_page, end_page + 1):
            tenders = await self.parse_page_list(page)
            self.tenders_list.extend(tenders)
            if page < end_page:
                await asyncio.sleep(1)

        logger.info(f"\n‚úì –ü–æ–ª—É—á–µ–Ω–æ {len(self.tenders_list)} —Ç–µ–Ω–¥–µ—Ä–æ–≤")
        self.save_tenders_list()

        if self.tenders_list:
            print("\n" + "=" * 70)
            print("–≠–¢–ê–ü 2: –ü–ê–†–°–ò–ù–ì –î–ï–¢–ê–õ–ï–ô")
            print("=" * 70)

            semaphore = asyncio.Semaphore(3)

            async def parse_with_semaphore(tender):
                async with semaphore:
                    return await self.parse_tender_detail(tender)

            tasks = [parse_with_semaphore(t) for t in self.tenders_list]
            results = await asyncio.gather(*tasks)

            # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ —Ç–∏–ø–∞–º
            for result in results:
                if result.get('type') == 'completed':
                    self.completed_tenders.append(result['data'])
                elif result.get('type') == 'published':
                    self.published_tenders.append(result['data'])

            logger.info(f"\n{'=' * 70}")
            logger.info(f"‚úì –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ: {len(self.completed_tenders)}")
            logger.info(f"‚úì –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ: {len(self.published_tenders)}")
            logger.info(f"{'=' * 70}\n")

            self.save_completed_tenders()
            self.save_published_tenders()

    def save_tenders_list(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞"""
        if not self.tenders_list:
            return None

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'tenders_list_{timestamp}.csv'

        fieldnames = ['code', 'description', 'customer', 'lots', 'planned_amount',
                      'purchase_amount', 'method', 'status', 'dates', 'detail_link']

        with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(self.tenders_list)

        logger.info(f"\n‚úÖ –°–ü–ò–°–û–ö: {filename} ({len(self.tenders_list)} –∑–∞–ø–∏—Å–µ–π)")
        return filename

    def save_completed_tenders(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö"""
        if not self.completed_tenders:
            return None

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'completed_tenders_{timestamp}.csv'

        all_keys = set()
        for t in self.completed_tenders:
            all_keys.update(t.keys())

        priority = ['tender_code', 'customer_name', 'customer_location', 'purchase_basis',
                    'lots_description', 'total_lots', 'skp_items', 'licenses',
                    'winner_supplier', 'winner_address', 'winner_price', 'local_content',
                    'suppliers', 'all_prices', 'purchase_code', 'signed_by', 'signed_date']

        fieldnames = [k for k in priority if k in all_keys]
        fieldnames.extend(sorted(all_keys - set(fieldnames)))

        with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(self.completed_tenders)

        logger.info(f"‚úÖ –ó–ê–í–ï–†–®–ï–ù–ù–´–ï: {filename} ({len(self.completed_tenders)} –∑–∞–ø–∏—Å–µ–π)")
        return filename

    def save_published_tenders(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö"""
        if not self.published_tenders:
            return None

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'published_tenders_{timestamp}.csv'

        all_keys = set()
        for t in self.published_tenders:
            all_keys.update(t.keys())

        priority = ['tender_code', 'customer_name', 'customer_location', 'web_resource',
                    'purchase_items', 'total_items', 'submission_start', 'submission_end',
                    'opening_date', 'contact_email', 'contact_phone',
                    'local_content_requirement', 'contract_deadline',
                    'signed_by', 'signed_date']

        fieldnames = [k for k in priority if k in all_keys]
        fieldnames.extend(sorted(all_keys - set(fieldnames)))

        with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(self.published_tenders)

        logger.info(f"‚úÖ –û–ü–£–ë–õ–ò–ö–û–í–ê–ù–ù–´–ï: {filename} ({len(self.published_tenders)} –∑–∞–ø–∏—Å–µ–π)")
        return filename


async def main():
    print("\n" + "=" * 70)
    print("–ü–ê–†–°–ï–† –¢–ï–ù–î–ï–†–û–í REESTR.NADLOC.KZ")
    print("–°–æ–∑–¥–∞–µ—Ç –¢–†–ò CSV —Ñ–∞–π–ª–∞:")
    print("  1. tenders_list_*.csv - —Å–ø–∏—Å–æ–∫ —Ç–µ–Ω–¥–µ—Ä–æ–≤")
    print("  2. completed_tenders_*.csv - –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ (–ø—Ä–æ—Ç–æ–∫–æ–ª—ã)")
    print("  3. published_tenders_*.csv - –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ (–æ–±—ä—è–≤–ª–µ–Ω–∏—è)")
    print("=" * 70)

    async with AdvancedTenderParser() as parser:
        await parser.parse_all(
            start_page=1,
            end_page=2  # –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ –Ω—É–∂–Ω–æ–µ
        )

        print("\n" + "=" * 70)
        print("‚úÖ –ó–ê–í–ï–†–®–ï–ù–û!")
        print(f"üìä –°–ø–∏—Å–æ–∫: {len(parser.tenders_list)}")
        print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ: {len(parser.completed_tenders)}")
        print(f"üì¢ –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ: {len(parser.published_tenders)}")
        print("=" * 70 + "\n")


if __name__ == "__main__":
    asyncio.run(main())